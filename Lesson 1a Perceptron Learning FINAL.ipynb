{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Lesson 1a: Perceptron Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this lesson you will implement one of the first algorithms from the history of neural networks: the perceptron.\n",
    "\n",
    "You will NOT be using Keras/Tensorflow or other machine learning toolkits for this problem. Instead, you will implement the perceptron learning rule yourself.\n",
    "\n",
    "Read over the code below. Much has already been done. Areas where you need to add your own code are marked with \"TODO\" comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the 'iris' dataset.\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # Use the first two features.\n",
    "y = iris.target\n",
    "x_min = min(X[:, 0])\n",
    "x_max = max(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data points.\n",
    "def make_plot():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    markers = ['o', 's', '_']\n",
    "    colors = 'tab:blue', 'tab:orange', 'tab:green'\n",
    "    for i, cat in enumerate(np.unique(y)):\n",
    "        plt.scatter(X[:, 0][y==cat], X[:, 1][y==cat], c=colors[i], marker=markers[i])\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.legend(['0: Setosa', '1: Versicolour', '2: Virginica'])\n",
    "make_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Build a perceptron to distinguish Setosa from the other two varieties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Versicolour and Virginica are intermixed in this plot; note that some datapoints have identical (length, width) values but differente categories! Thus, we will focus on distinguishing Setosa from the other two, because perceptrons require data to be linearlly separable.\n",
    "\n",
    "The perceptron will have a simple structure:\n",
    "    \n",
    "    * Two input nodes: one for Sepal length, one for Sepal width.\n",
    "    * One output node: the output will be 0 for Setosa (category 0), and 1 for either of the other two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \"\"\"Simple perceptron with 2 inputs and 1 output.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize the perceptron weights and the bias term.\n",
    "        self._w = [0, 0]\n",
    "        self._b = 0\n",
    "    \n",
    "    def predict(self, x, verbose=False):\n",
    "        \"\"\"x is the input weight vector. Output is the result of running the perceptron on this input.\n",
    "        \n",
    "        Implement the Perceptron rule that involves multiplying weights by input, adding in bias, using a threshold, etc.\n",
    "        \n",
    "        The returned output should be 1 or 0.\n",
    "        \n",
    "        Use the \"verbose\" flag to print debugging info if desired.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        \n",
    "        if verbose:\n",
    "            # Print computation results here if desired.\n",
    "            pass\n",
    "        \n",
    "        # TODO\n",
    "        return 0\n",
    "        \n",
    "    def accuracy(self, x, y):\n",
    "        \"\"\"Compute the total % accuracy over a set of inputs x and corresponding outputs y.\"\"\"\n",
    "        correct = 0\n",
    "        for i in range(len(x)):\n",
    "            example_x = x[i]\n",
    "            example_y = y[i]\n",
    "            if self.predict(example_x) == example_y:\n",
    "                correct += 1\n",
    "        return float(correct) / len(x)\n",
    "            \n",
    "    def update_weights(self, x, target, verbose=False):\n",
    "        \"\"\"Update the perceptron's weights according to the perceptron learning rule.\n",
    "        \n",
    "        x is an input example, and target is the desired output.\n",
    "        \n",
    "        This function should modify self._b and self._w. It has no return value.\n",
    "        \n",
    "        Use the \"verbose\" flag to print debugging info if desired.\n",
    "        \"\"\"\n",
    "        current_output = self.predict(x)\n",
    "\n",
    "        # TODO\n",
    "        \n",
    "    def train(self, x, y, num_iterations, verbose=False):\n",
    "        \"\"\"Train the perceptron for the given number of iterations on the input data x with \n",
    "        corresponding target values y.\n",
    "        \n",
    "        Use the \"verbose\" flag to print debugging info if desired.\n",
    "        \"\"\"\n",
    "        assert(len(x) == len(y))\n",
    "        for i in range(num_iterations):\n",
    "            print('Iter #%d' % i)\n",
    "            for j in range(len(x)):\n",
    "                example_x = x[j]\n",
    "                example_y = y[j]\n",
    "\n",
    "                # Train the perceptron on this input/output example pair (example_x, example_y).\n",
    "                # This should update the perceptron's weights.\n",
    "                \n",
    "                # TODO\n",
    "                \n",
    "                if verbose:\n",
    "                    pass\n",
    "                    # TODO\n",
    "                    \n",
    "            # Print some useful info during training.\n",
    "            print('Weights:', self._w)\n",
    "            print('Bias:', self._b)  \n",
    "            acc = self.accuracy(x, y)\n",
    "            print('Accuracy: %.3f%%' % (acc * 100))\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset for training a Setosa/not-Setosa classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_shuffled_data(x, y):\n",
    "    \"\"\"Convenient function to shuffle data and outputs, to inject some randomness into training.\"\"\"\n",
    "    # Create shuffle pattern of indices.\n",
    "    s = np.arange(x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    \n",
    "    # Apply suffle pattern to x and y.\n",
    "    x_shuffled = x[s]\n",
    "    y_shuffled = y[s]\n",
    "    return x_shuffled, y_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Map data labels to just two categories.\n",
    "y_two_categories = np.array([0 if i==0 else 1 for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled = get_shuffled_data(X, y_two_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train a perceptron on the shuffled data\n",
    "Try to get as high an accuracy as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "p = Perceptron()\n",
    "\n",
    "# TODO: Train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Plot the learned perceptron decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Our perceptron makes decisions based on the value of b + w1x1 + w2x2. We can set this to 0 and solve to find the decision boundary. \n",
    "\n",
    "Complete the function below to compute x2 (the y axis in the plot above) as a function of b, w1, x1, w2 for a given perceptron:  \n",
    "x2 = (-b - w1x1) / w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_y_decision_boundary(x1, perceptron):\n",
    "    x2 = 0\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Compute the decision boundary for the perceptron trained above, and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y1 = get_y_decision_boundary(x_min, p)\n",
    "y2 = get_y_decision_boundary(x_max, p)\n",
    "y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "make_plot()\n",
    "plt.plot([x_min,x_max], [y1,y2], ls='dashed', c='tab:red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Another model: Virginica/not-Virginica classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Build a new model, but grouping categories 0 and 1 together, trying to separate out Virginica from the other two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_two_categories_2 = np.array([0 if i==2 else 1 for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled = get_shuffled_data(X, y_two_categories_2)\n",
    "p2 = Perceptron()\n",
    "\n",
    "# Train the perceptron\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the decision boundary and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y1 = get_y_decision_boundary(x_min, p2)\n",
    "y2 = get_y_decision_boundary(x_max, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "make_plot()\n",
    "plt.plot([x_min,x_max], [y1,y2], ls='dashed', c='tab:red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Discuss the results in the cell below. How did the two perceptrons compare? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Discuss here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
